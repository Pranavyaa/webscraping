import re
import urllib.request, urllib.parse, urllib.error
from bs4 import BeautifulSoup
import ssl


ctx = ssl.create_default_context()
ctx.check_hostname = False
ctx.verify_mode = ssl.CERT_NONE
fhand1=open("data1.txt",'w',encoding='utf8')


url ="https://www.mahabalipuram.co.in/"
html = urllib.request.urlopen(url, context=ctx).read()
soup = BeautifulSoup(html, 'html.parser')


#for finding a sub links in this website

links=[]
for link in soup.findAll('a', attrs={'href': re.compile("php$")}):
    links.append(link.get('href'))


#taking complete links
whole_link=[]
for link in links:
    url1=url.rstrip()+link
    whole_link.append(url1)



for link in whole_link:
    url =link
    fhand1.write("=========================================================================================================")
    fhand1.write("\n")
    fhand1.write(url)
    fhand1.write("\n")
    headers = {}
    headers['User-Agent'] = "Mozilla/5.0 (X11; Linux i686)"

    req = urllib.request.Request(url, headers=headers)
    resp = urllib.request.urlopen(req)
    resp_data = resp.read()

    soup = BeautifulSoup(resp_data, 'html.parser')

    lst1 = soup.find_all('p')
    for data in lst1:
        if (data.text == None):
            continue
        if (len(data.text)<100):
            continue

        fhand1.write(data.text)
        fhand1.write("\n")

    fhand1.write("=========================================================================================================")

